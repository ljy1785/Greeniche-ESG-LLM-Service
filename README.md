# 🌿 Greeniche (그리니치): ESG 공시 자동화 & 가이드 솔루션
## 📂 프로젝트 발표 자료
[👉 발표 자료 PDF 다운로드](./(엣취)_프로젝트_소개서.pdf)
> **2023 LLM Innovators Challenge 본선 진출작**

> **역할:** 팀장(PM), 데이터 전처리 전략 수립, BERT 모델 파인튜닝 및 성능 분석

## 1. 프로젝트 개요
기업들이 ESG 경영 보고서를 작성할 때, 복잡한 국제 표준(ESRS, GRI)을 일일이 대조해야 하는 비효율을 해결하기 위한 **LLM 기반 자동 매핑 및 가이드 서비스**.
사용자가 보고서 초안을 업로드하면, 해당 내용이 국제 표준의 어떤 항목에 해당하는지 분석하고 가이드를 제공.

* **팀 구성:** 5명
* **주요 기능:**
    * ESG 공시 표준(ESRS/GRI) 자동 매핑
    * 사용자 질문에 대한 근거 기반 답변 제공 (RAG)
    * ESG 보고서 작성 가이드라인 제시

## 2. 기술 스택
* **Language:** Python
* **Model:** Upstage Solar LLM, BERT (Baseline)
* **Data Processing:** Pandas (Chunking Logic)
* **Collaboration:** Notion

## 3. 시스템 아키텍처
<img width="1083" height="479" alt="image" src="https://github.com/user-attachments/assets/76d4e720-fc1a-4e93-a7c1-bb6cc49b95c9" />

1.  **Document Parser:** PDF/HTML 형태의 보고서에서 불필요한 태그를 제거하고 텍스트를 추출.
2.  **Embedding:** 추출된 텍스트와 ESG 표준(ESRS/GRI) 데이터를 벡터화하여 Pinecone에 저장.
3.  **Retriever:** 사용자의 질문(Query)과 가장 유사한 표준 규정을 검색.
4.  **Generator (Solar LLM):** 검색된 근거 자료(Context)를 바탕으로 환각 없는 답변 생성.

## 4.  기여
**팀장**으로서 프로젝트의 방향성을 잡고, **데이터/모델 실험 파트**에 주로 참여
### 🛠 A. LLM의 문맥 이해를 돕는 데이터 청킹(Chunking) 전략 수립
* **문제:** ESG 보고서는 텍스트 길이가 매우 길어, 모델에 그대로 입력할 경우 문맥이 잘리거나 주요 정보를 놓치는 문제 발생.
* **해결:**
    * 문장을 단순히 자르지 않고 의미 단위로 보존하기 위해 `Sliding Window` 기법을 적용.
    * BERT 모델의 입력 제한(512 token)을 고려하여 최적의 길이로 데이터를 분할, 모델이 문맥을 놓치지 않도록 전처리 로직 구현.

### 🧪 B. BERT 파인튜닝을 통한 베이스라인 성능 검증
최적의 답변 성능을 찾기 위해 **파인튜닝(Fine-tuning) 방식**을 직접 실험하고 분석.

* **시도:** 기업 보고서 데이터로 BERT 모델을 파인튜닝하여 도메인 특화 모델 개발 시도.
* **분석:** 파인튜닝 모델이 학습 데이터 내에서는 잘 작동하지만, 새로운 기업 데이터나 최신 개정안에 대해서는 유연성이 부족함을 확인.
* **기여:** 파인튜닝 모델의 한계를 명확히 데이터로 검증.

## 5. 회고 (Lessons Learned)
* **서비스 vs 기술의 균형:** 공모전 특성상 완성된 서비스 형태가 중요했으나, 초반에 모델 성능(파인튜닝)에 너무 집중하다 보니 서비스 기능 구현 시간이 부족했던 점이 아쉬움. 기술적 깊이만큼이나 '사용자 경험(Service)'을 고려한 일정 관리의 중요성을 배움.

